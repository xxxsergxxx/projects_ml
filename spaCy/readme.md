# Sentiment Classification using IMDb Dataset

## ğŸ“ Task

Binary classification of movie reviews into **positive** or **negative** sentiments using Natural Language Processing (NLP) and Machine Learning.

---

## ğŸ“ Dataset

**Source:** IMDB Dataset of 50K Movie Reviews  
**Columns:**

- `review` â€” raw text of the review  
- `sentiment` â€” label: `"positive"` or `"negative"`

---

## ğŸ§¼ Data Cleaning & Preprocessing

- Removed:
  - HTML tags
  - URLs
  - Punctuation
  - Digits
- Converted text to lowercase
- Lemmatization via spaCy
- Removed stopwords (`spaCy.STOP_WORDS`)
- Converted target labels:  
  `"positive"` â†’ `1`, `"negative"` â†’ `0`

Example of preprocessing:
- Original: `"One of the other reviewers has mentioned..."`
- Cleaned: `"one reviewer mention watch oz episode hook ..."`

---

âš™ï¸ Model Training
âœ… LightGBM Classifier

LGBMClassifier(
    learning_rate=0.069,
    n_estimators=100,
    num_leaves=27,
    random_state=42
)

Best parameters (GridSearchCV):

{"num_leaves": 27}

---

ğŸ“Š Evaluation (LightGBM)

Metrics:

    Accuracy: 0.84

    Precision: 0.85 (class 0), 0.83 (class 1)

    Recall: 0.83 (class 0), 0.86 (class 1)

Confusion Matrix:

[[4096  865]
 [ 701 4338]]

 ğŸ§  Stacking Classifier

Base learners:

    KNeighborsClassifier

    LGBMClassifier

Meta-learner:

    SVC
---

ğŸ“ˆ Stacking Classifier Results

Metrics:

    Accuracy: 0.88

    Precision: 0.89 (class 0), 0.87 (class 1)

    Recall: 0.86 (class 0), 0.89 (class 1)

    ROC AUC: 0.949
---

ğŸ“Š Model Comparison
Model	Accuracy	ROC AUC	Notes
LightGBM	0.84	â€“	Fast, simple baseline
Stacking (KNN + LGBM â†’ SVC)	0.88	0.949	Best performance overall
---

ğŸ“š Libraries Used

    spaCy

    scikit-learn

    lightgbm

    matplotlib, seaborn

    TfidfVectorizer, StackingClassifier
---

ğŸ“Œ Notes

    Data cleaned using regex and spaCy

    Text transformed with TF-IDF

    Model stacking improves results

    LightGBM is a strong baseline
